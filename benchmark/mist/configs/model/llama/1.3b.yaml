# @package _global_

defaults:
  - /model/llama/common.yaml
  - _self_

model:
  name: llama-1.3b
  hidden_size: 2048
  intermediate_size: 5632
  num_hidden_layers: 24
  num_attention_heads: 16
  num_heads_kv: ~