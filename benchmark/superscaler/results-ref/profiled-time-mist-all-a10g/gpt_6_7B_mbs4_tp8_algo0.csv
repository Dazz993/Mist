op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,58422.017,3670.192,0.031,64.000,66.000,64.070,191.930,272.000
enc-1st-layernorm,383.180,1412.487,64.000,128.000,0.000,64.062,0.000,512.000
enc-attention-qkv,1756.996,61067.408,128.000,88.000,12.000,24.000,0.000,212.000
enc-attention-score,356.495,820.029,88.000,200.000,0.000,128.000,128.000,296.000
enc-attention-softmax,450.879,565.624,200.000,200.000,0.000,128.000,0.000,384.000
enc-attention-dropout,706.536,691.694,200.000,200.000,0.000,192.000,0.000,512.000
enc-attention-context,427.049,722.444,200.000,72.000,0.000,8.000,12.000,144.000
enc-attention-dense,58764.696,1095.414,72.000,128.008,4.000,64.000,0.000,212.000
enc-post-attention-dropout,1052.994,625.318,128.008,64.000,0.000,96.000,64.000,316.000
enc-2nd-layernorm,373.077,1409.584,64.000,128.000,0.000,64.062,0.000,512.000
enc-MLP-GEMM-1,2166.355,61544.794,128.000,96.004,16.000,32.000,0.000,160.000
enc-MLP-gelu,148.726,296.843,96.004,96.000,0.000,32.000,0.000,188.000
enc-MLP-GEMM-2,60593.653,4139.614,96.000,128.008,16.000,64.000,0.000,224.000
enc-post-MLP-dropout,1049.393,623.894,128.008,64.000,0.000,96.000,64.000,316.000
final-layernorm,672.770,998.169,64.000,64.000,0.000,128.062,0.000,256.000
gpt-post-process,11052.608,69074.380,64.000,0.000,50.000,200.102,99.898,0.000
