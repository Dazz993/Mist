op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,5674.911,1498.222,0.016,16.000,58.000,16.035,47.965,134.000
enc-1st-layernorm,81.789,343.478,16.000,32.000,0.000,16.031,0.000,128.000
enc-attention-qkv,16838.694,1307.917,20.000,64.000,6.000,48.000,48.000,204.000
enc-attention-score,348.300,638.121,40.000,160.000,0.000,128.000,128.000,256.000
enc-attention-softmax,451.493,565.553,160.000,160.000,0.000,128.000,0.000,384.000
enc-attention-dropout,705.725,691.646,160.000,160.000,0.000,192.000,0.000,512.000
enc-attention-context,329.173,641.090,160.000,32.000,0.000,4.000,0.000,148.000
enc-attention-dense,5520.630,333.881,32.000,44.004,2.000,16.000,0.000,48.000
enc-post-attention-dropout,271.612,162.584,44.004,28.000,0.000,24.000,28.000,124.000
enc-2nd-layernorm,81.027,333.571,28.000,44.000,0.000,16.031,0.000,128.000
enc-MLP-GEMM-1,650.460,6386.399,44.000,44.004,8.000,16.000,0.000,64.000
enc-MLP-gelu,81.587,164.056,44.004,44.000,0.000,16.000,0.000,124.000
enc-MLP-GEMM-2,5971.169,1109.767,44.000,44.004,8.000,16.000,0.000,64.000
enc-post-MLP-dropout,271.523,162.584,44.004,28.000,0.000,24.000,28.000,124.000
final-layernorm,154.871,469.434,28.000,28.000,0.000,32.031,0.000,64.000
gpt-post-process,7784.665,13220.507,28.000,12.000,50.000,200.051,99.949,0.000
