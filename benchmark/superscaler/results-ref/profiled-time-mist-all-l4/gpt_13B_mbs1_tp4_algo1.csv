op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,7027.364,3553.414,0.008,20.000,145.000,20.018,0.000,186.000
enc-1st-layernorm,113.195,579.768,20.000,40.000,0.000,20.016,0.000,160.000
enc-attention-qkv,21242.929,1457.214,25.000,80.000,37.500,60.000,60.000,180.000
enc-attention-score,361.317,832.236,50.000,120.000,0.000,80.000,80.000,180.000
enc-attention-softmax,6523.609,10800.672,120.000,120.000,0.000,240.000,160.000,560.000
enc-attention-dropout,914.830,908.512,120.000,120.000,0.000,120.000,0.000,320.000
enc-attention-context,455.725,811.476,120.000,40.000,0.000,5.000,0.000,110.000
enc-attention-dense,6911.325,343.227,40.000,55.010,12.500,20.000,0.000,60.000
enc-post-attention-dropout,530.660,262.064,55.010,35.000,0.000,30.000,10.000,126.000
enc-2nd-layernorm,113.863,580.919,35.000,55.000,0.000,20.016,0.000,160.000
enc-MLP-GEMM-1,1881.921,7971.352,55.000,55.010,50.000,20.000,0.000,80.000
enc-MLP-gelu,156.999,217.146,55.010,55.000,0.000,20.000,0.000,126.000
enc-MLP-GEMM-2,8004.570,1360.059,55.000,55.010,50.000,20.000,0.000,80.000
enc-post-MLP-dropout,533.062,264.013,55.010,35.000,0.000,30.000,10.000,126.000
final-layernorm,114.363,332.510,35.000,35.000,0.000,20.016,0.000,80.000
gpt-post-process,7416.868,11308.819,35.000,15.000,125.000,100.025,49.975,0.000
