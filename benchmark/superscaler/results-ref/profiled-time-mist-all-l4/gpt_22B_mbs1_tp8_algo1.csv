op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,9056.282,3166.389,0.008,24.000,99.000,24.018,23.982,172.000
enc-1st-layernorm,181.955,799.376,24.000,48.000,0.000,24.016,0.000,192.000
enc-attention-qkv,27396.727,1688.075,27.000,96.000,27.000,72.000,72.000,216.000
enc-attention-score,362.146,591.499,54.000,112.000,0.000,64.000,64.000,128.000
enc-attention-softmax,437.212,573.635,112.000,112.000,0.000,64.000,0.000,192.000
enc-attention-dropout,729.173,725.609,112.000,112.000,0.000,96.000,0.000,256.000
enc-attention-context,349.915,661.659,112.000,48.000,0.000,3.000,0.000,84.000
enc-attention-dense,8843.732,326.633,48.000,69.012,9.000,24.000,0.000,72.000
enc-post-attention-dropout,700.575,353.748,69.012,45.000,0.000,36.000,24.000,142.000
enc-2nd-layernorm,180.554,797.170,45.000,69.000,0.000,24.016,0.000,192.000
enc-MLP-GEMM-1,1169.533,9466.785,69.000,57.006,36.000,12.000,0.000,60.000
enc-MLP-gelu,56.267,98.932,57.006,57.000,0.000,12.000,0.000,92.000
enc-MLP-GEMM-2,9646.630,917.983,57.000,69.012,36.000,24.000,0.000,84.000
enc-post-MLP-dropout,697.118,353.163,69.012,45.000,0.000,36.000,24.000,142.000
final-layernorm,179.529,474.381,45.000,45.000,0.000,24.016,0.000,96.000
gpt-post-process,3437.489,11042.720,45.000,21.000,75.000,50.025,25.975,0.000
