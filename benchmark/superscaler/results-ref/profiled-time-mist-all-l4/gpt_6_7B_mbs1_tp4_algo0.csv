op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,5479.455,2878.571,0.008,16.000,116.000,16.018,0.000,116.000
enc-1st-layernorm,73.457,374.264,16.000,32.000,0.000,16.016,0.000,128.000
enc-attention-qkv,942.278,5945.629,32.000,28.000,24.000,12.000,0.000,48.000
enc-attention-score,284.624,630.313,28.000,84.000,0.000,64.000,64.000,148.000
enc-attention-softmax,440.621,577.974,84.000,84.000,0.000,64.000,0.000,192.000
enc-attention-dropout,727.725,728.261,84.000,84.000,0.000,96.000,0.000,256.000
enc-attention-context,357.831,644.428,84.000,20.000,0.000,4.000,0.000,84.000
enc-attention-dense,5448.103,224.638,20.000,32.008,8.000,16.000,0.000,68.000
enc-post-attention-dropout,359.702,172.663,32.008,16.000,0.000,24.000,8.000,108.000
enc-2nd-layernorm,73.153,372.165,16.000,32.000,0.000,16.016,0.000,128.000
enc-MLP-GEMM-1,1076.645,6099.534,32.000,32.008,32.000,16.000,0.000,64.000
enc-MLP-gelu,70.482,101.048,32.008,32.000,0.000,16.000,0.000,108.000
enc-MLP-GEMM-2,6112.909,884.295,32.000,32.008,32.000,16.000,0.000,64.000
enc-post-MLP-dropout,363.469,169.182,32.008,16.000,0.000,24.000,8.000,108.000
final-layernorm,73.439,340.873,16.000,16.000,0.000,16.016,0.000,64.000
gpt-post-process,6725.550,9334.600,16.000,0.000,100.000,100.025,49.975,0.000
