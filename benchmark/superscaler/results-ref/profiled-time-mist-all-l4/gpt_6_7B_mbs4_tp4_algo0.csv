op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,23361.492,6799.412,0.031,64.000,116.000,64.070,191.930,560.000
enc-1st-layernorm,563.455,2322.388,64.000,128.000,0.000,64.062,0.000,512.000
enc-attention-qkv,4634.869,23216.259,128.000,112.000,24.000,48.000,16.000,208.000
enc-attention-score,1319.581,2757.978,112.000,336.000,0.000,256.000,256.000,560.000
enc-attention-softmax,1722.914,2245.307,336.000,336.000,0.000,256.000,0.000,768.000
enc-attention-dropout,2934.062,2908.736,336.000,336.000,0.000,384.000,0.000,1024.000
enc-attention-context,1452.690,2547.932,336.000,80.000,0.000,16.000,16.000,304.000
enc-attention-dense,21516.562,769.305,80.000,128.008,8.000,64.000,0.000,208.000
enc-post-attention-dropout,2149.028,1297.015,128.008,64.000,0.000,96.000,64.000,300.000
enc-2nd-layernorm,565.189,2316.207,64.000,128.000,0.000,64.062,0.000,512.000
enc-MLP-GEMM-1,5092.531,23360.825,128.000,128.008,32.000,64.000,0.000,256.000
enc-MLP-gelu,577.742,1053.065,128.008,128.000,0.000,64.000,0.000,300.000
enc-MLP-GEMM-2,24008.203,2916.384,128.000,128.008,32.000,64.000,0.000,256.000
enc-post-MLP-dropout,2152.050,1297.241,128.008,64.000,0.000,96.000,64.000,300.000
final-layernorm,1137.161,1481.289,64.000,64.000,0.000,128.062,0.000,256.000
gpt-post-process,25608.540,42005.545,64.000,0.000,100.000,400.102,199.898,0.000
