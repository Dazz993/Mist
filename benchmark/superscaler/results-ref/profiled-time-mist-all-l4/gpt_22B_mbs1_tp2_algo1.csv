op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,6725.097,7084.107,0.008,24.000,324.000,24.018,0.000,396.000
enc-1st-layernorm,183.457,799.495,24.000,48.000,0.000,24.016,0.000,192.000
enc-attention-qkv,22116.184,4245.234,36.000,96.000,108.000,72.000,0.000,228.000
enc-attention-score,1264.840,2631.199,72.000,304.000,0.000,256.000,256.000,548.000
enc-attention-softmax,1724.464,2243.727,304.000,304.000,0.000,256.000,0.000,768.000
enc-attention-dropout,2938.300,2907.914,304.000,304.000,0.000,384.000,0.000,1024.000
enc-attention-context,1393.926,2484.918,304.000,48.000,0.000,12.000,12.000,292.000
enc-attention-dense,7340.145,927.067,48.000,60.012,36.000,24.000,0.000,84.000
enc-post-attention-dropout,696.868,363.672,60.012,36.000,0.000,36.000,24.000,142.000
enc-2nd-layernorm,181.550,794.947,36.000,60.000,0.000,24.016,0.000,192.000
enc-MLP-GEMM-1,6265.676,9997.439,60.000,84.023,144.000,48.000,0.000,168.000
enc-MLP-gelu,446.558,774.938,84.023,84.000,0.000,48.000,0.000,240.000
enc-MLP-GEMM-2,10091.782,3613.400,84.000,60.012,144.000,24.000,0.000,120.000
enc-post-MLP-dropout,702.488,359.094,60.012,36.000,0.000,36.000,24.000,142.000
final-layernorm,184.494,469.410,36.000,36.000,0.000,24.016,0.000,96.000
gpt-post-process,15668.100,16487.759,36.000,12.000,300.000,200.025,99.975,0.000
