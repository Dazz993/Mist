op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,262.135,7894.254,0.008,16.000,416.000,16.000,0.000,432.000
enc-1st-layernorm,87.583,411.510,16.000,32.000,0.000,16.016,0.000,128.000
enc-attention-qkv,4340.345,4150.039,32.000,64.000,96.000,48.000,48.000,160.000
enc-attention-score,1465.046,2759.451,64.000,288.000,0.000,256.000,256.000,560.000
enc-attention-softmax,1726.931,2247.334,288.000,288.000,0.000,256.000,0.000,768.000
enc-attention-dropout,2931.881,2903.080,288.000,288.000,0.000,384.000,0.000,1024.000
enc-attention-context,1453.584,2547.354,288.000,32.000,0.000,16.000,16.000,304.000
enc-attention-dense,1202.840,1328.856,32.000,32.008,32.000,16.000,0.000,64.000
enc-post-attention-dropout,382.715,171.602,32.008,16.000,0.000,24.000,8.000,108.000
enc-2nd-layernorm,73.385,379.419,16.000,32.000,0.000,16.016,0.000,128.000
enc-MLP-GEMM-1,5111.110,5661.440,32.000,80.031,128.000,64.000,0.000,208.000
enc-MLP-gelu,588.530,1055.133,80.031,80.000,0.000,64.000,0.000,304.000
enc-MLP-GEMM-2,7910.609,5263.281,80.000,32.008,128.000,16.000,0.000,112.000
enc-post-MLP-dropout,364.399,174.290,32.008,16.000,0.000,24.000,8.000,108.000
final-layernorm,74.631,341.541,16.000,16.000,0.000,16.016,0.000,64.000
gpt-post-process,26534.432,16660.607,16.000,0.000,400.000,400.025,199.975,0.000
