op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,5479.455,2878.571,0.008,16.000,116.000,16.018,0.000,116.000
enc-1st-layernorm,73.457,374.264,16.000,32.000,0.000,16.016,0.000,128.000
enc-attention-qkv,16825.700,988.936,20.000,64.000,24.000,48.000,48.000,128.000
enc-attention-score,284.624,630.313,40.000,96.000,0.000,64.000,64.000,148.000
enc-attention-softmax,440.621,577.974,96.000,96.000,0.000,64.000,0.000,192.000
enc-attention-dropout,727.725,728.261,96.000,96.000,0.000,96.000,0.000,256.000
enc-attention-context,357.831,644.428,96.000,32.000,0.000,4.000,0.000,84.000
enc-attention-dense,5426.836,223.398,32.000,44.008,8.000,16.000,0.000,68.000
enc-post-attention-dropout,359.702,172.663,44.008,28.000,0.000,24.000,8.000,108.000
enc-2nd-layernorm,73.153,372.165,28.000,44.000,0.000,16.016,0.000,128.000
enc-MLP-GEMM-1,1053.035,6116.414,44.000,44.008,32.000,16.000,0.000,64.000
enc-MLP-gelu,70.482,101.048,44.008,44.000,0.000,16.000,0.000,108.000
enc-MLP-GEMM-2,6101.394,867.939,44.000,44.008,32.000,16.000,0.000,64.000
enc-post-MLP-dropout,363.469,169.182,44.008,28.000,0.000,24.000,8.000,108.000
final-layernorm,73.439,340.873,28.000,28.000,0.000,16.016,0.000,64.000
gpt-post-process,6725.550,9334.600,28.000,12.000,100.000,100.025,49.975,0.000
