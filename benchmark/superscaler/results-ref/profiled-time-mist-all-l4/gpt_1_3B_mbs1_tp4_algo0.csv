op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,2812.409,1514.578,0.008,8.000,58.000,8.018,31.982,86.000
enc-1st-layernorm,69.064,107.282,8.000,16.000,0.000,8.016,0.000,72.000
enc-attention-qkv,234.985,2944.851,16.000,14.000,6.000,6.000,0.000,20.000
enc-attention-score,309.491,607.079,14.000,74.000,0.000,64.000,64.000,128.000
enc-attention-softmax,440.484,569.242,74.000,74.000,0.000,64.000,0.000,192.000
enc-attention-dropout,725.985,741.780,74.000,74.000,0.000,96.000,0.000,256.000
enc-attention-context,311.297,638.306,74.000,10.000,0.000,2.000,0.000,64.000
enc-attention-dense,2820.551,230.718,10.000,16.004,2.000,8.000,0.000,36.000
enc-post-attention-dropout,106.692,200.224,16.004,8.000,0.000,12.000,8.000,72.000
enc-2nd-layernorm,71.150,225.544,8.000,16.000,0.000,8.016,11.984,72.000
enc-MLP-GEMM-1,262.344,2957.875,16.000,16.004,8.000,8.000,0.000,36.000
enc-MLP-gelu,68.855,250.793,16.004,16.000,0.000,8.000,12.000,68.000
enc-MLP-GEMM-2,2979.463,244.218,16.000,16.004,8.000,8.000,0.000,36.000
enc-post-MLP-dropout,94.682,189.966,16.004,8.000,0.000,12.000,8.000,72.000
final-layernorm,76.205,431.967,8.000,8.000,0.000,8.016,11.984,36.000
gpt-post-process,5764.872,5704.790,8.000,0.000,50.000,100.025,49.975,0.000
