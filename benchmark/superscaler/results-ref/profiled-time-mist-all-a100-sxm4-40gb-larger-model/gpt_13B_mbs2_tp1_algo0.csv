op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1164.806,3087.294,0.031,80.000,540.000,80.000,240.000,932.000
enc-1st-layernorm,184.745,681.990,80.000,160.000,0.000,80.062,0.000,640.000
enc-attention-qkv,6014.657,5388.474,160.000,320.000,150.000,240.000,240.000,800.000
enc-attention-score,3583.604,4831.469,320.000,2720.000,0.000,2560.000,2560.000,5360.000
enc-attention-softmax,6066.465,6092.548,2720.000,2720.000,0.000,2560.000,0.000,7680.000
enc-attention-dropout,5905.294,4880.381,2720.000,2720.000,0.000,3840.000,0.000,10240.000
enc-attention-context,2496.397,5835.766,2720.000,160.000,0.000,80.000,80.000,2800.000
enc-attention-dense,1695.520,1618.952,160.000,160.010,50.000,80.000,0.000,320.000
enc-post-attention-dropout,566.465,290.340,160.010,80.000,0.000,120.000,80.000,430.000
enc-2nd-layernorm,186.056,705.159,80.000,160.000,0.000,80.062,0.000,640.000
enc-MLP-GEMM-1,6699.467,6377.292,160.000,400.039,200.000,320.000,0.000,1040.000
enc-MLP-gelu,577.778,1065.528,400.039,400.000,0.000,320.000,0.000,1390.000
enc-MLP-GEMM-2,6803.751,6394.982,400.000,160.010,200.000,80.000,0.000,560.000
enc-post-MLP-dropout,567.424,282.484,160.010,80.000,0.000,120.000,80.000,430.000
final-layernorm,399.798,527.465,80.000,80.000,0.000,160.062,0.000,320.000
gpt-post-process,26910.716,19164.813,80.000,0.000,500.000,1600.102,799.898,0.000
