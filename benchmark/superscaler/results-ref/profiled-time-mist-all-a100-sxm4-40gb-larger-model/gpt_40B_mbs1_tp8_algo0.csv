op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1509.178,2087.975,0.016,64.000,164.000,64.035,127.965,412.000
enc-1st-layernorm,209.981,615.007,64.000,128.000,0.000,64.031,0.000,512.000
enc-attention-qkv,914.359,1684.546,128.000,88.000,48.000,24.000,0.000,140.000
enc-attention-score,391.132,497.246,88.000,328.000,0.000,256.000,256.000,552.000
enc-attention-softmax,621.837,623.578,328.000,328.000,0.000,256.000,0.000,768.000
enc-attention-dropout,579.613,492.054,328.000,328.000,0.000,384.000,0.000,1024.000
enc-attention-context,262.851,630.182,328.000,72.000,0.000,8.000,12.000,272.000
enc-attention-dense,952.256,268.954,72.000,128.016,16.000,64.000,0.000,192.000
enc-post-attention-dropout,441.974,226.933,128.016,64.000,0.000,96.000,64.000,364.000
enc-2nd-layernorm,203.359,619.572,64.000,128.000,0.000,64.031,0.000,512.000
enc-MLP-GEMM-1,1060.462,1877.850,128.000,96.008,64.000,32.000,0.000,160.000
enc-MLP-gelu,63.103,126.833,96.008,96.000,0.000,32.000,0.000,236.000
enc-MLP-GEMM-2,1819.992,1007.617,96.000,128.016,64.000,64.000,0.000,224.000
enc-post-MLP-dropout,443.655,227.284,128.016,64.000,0.000,96.000,64.000,364.000
final-layernorm,205.094,467.926,64.000,64.000,0.000,64.031,0.000,256.000
gpt-post-process,2787.590,2731.812,64.000,0.000,100.000,100.051,49.949,0.000
