op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1169.002,1631.951,0.016,48.000,123.000,48.035,0.000,356.000
enc-1st-layernorm,126.994,440.866,48.000,96.000,0.000,48.031,0.000,384.000
enc-attention-qkv,2454.901,794.572,54.000,192.000,27.000,144.000,144.000,432.000
enc-attention-score,370.449,492.954,108.000,352.000,0.000,256.000,256.000,532.000
enc-attention-softmax,622.344,620.556,352.000,352.000,0.000,256.000,0.000,768.000
enc-attention-dropout,579.005,492.150,352.000,352.000,0.000,384.000,0.000,1024.000
enc-attention-context,259.340,612.777,352.000,96.000,0.000,6.000,14.000,276.000
enc-attention-dense,709.689,169.164,96.000,138.012,9.000,48.000,0.000,164.000
enc-post-attention-dropout,336.564,172.317,138.012,90.000,0.000,72.000,48.000,300.000
enc-2nd-layernorm,125.694,440.741,90.000,138.000,0.000,48.031,0.000,384.000
enc-MLP-GEMM-1,640.517,1317.769,138.000,114.006,36.000,24.000,0.000,120.000
enc-MLP-gelu,49.257,96.351,114.006,114.000,0.000,24.000,0.000,192.000
enc-MLP-GEMM-2,1245.987,606.102,114.000,138.012,36.000,48.000,0.000,168.000
enc-post-MLP-dropout,336.576,172.484,138.012,90.000,0.000,72.000,48.000,300.000
final-layernorm,125.623,331.020,90.000,90.000,0.000,48.031,0.000,192.000
gpt-post-process,2330.714,2318.072,90.000,42.000,75.000,100.051,49.949,0.000
