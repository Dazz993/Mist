op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,2120.399,2266.955,0.031,80.000,102.500,80.070,239.930,398.000
enc-1st-layernorm,183.511,678.557,80.000,160.000,0.000,80.062,0.000,640.000
enc-attention-qkv,3860.009,1170.129,90.000,320.000,18.750,240.000,240.000,720.000
enc-attention-score,473.100,601.774,180.000,480.000,0.000,320.000,320.000,670.000
enc-attention-softmax,4892.349,7820.654,480.000,480.000,0.000,960.000,640.000,2240.000
enc-attention-dropout,719.678,617.474,480.000,480.000,0.000,480.000,0.000,1280.000
enc-attention-context,338.006,757.647,480.000,160.000,0.000,10.000,0.000,350.000
enc-attention-dense,1079.822,213.259,160.000,230.010,6.250,80.000,0.000,250.000
enc-post-attention-dropout,550.026,280.792,230.010,150.000,0.000,120.000,80.000,430.000
enc-2nd-layernorm,180.846,678.414,150.000,230.000,0.000,80.062,0.000,640.000
enc-MLP-GEMM-1,811.970,1776.332,230.000,190.005,25.000,40.000,0.000,200.000
enc-MLP-gelu,77.790,154.555,190.005,190.000,0.000,40.000,0.000,270.000
enc-MLP-GEMM-2,1795.214,756.836,190.000,230.010,25.000,80.000,0.000,280.000
enc-post-MLP-dropout,552.255,280.237,230.010,150.000,0.000,120.000,80.000,430.000
final-layernorm,382.245,492.144,150.000,150.000,0.000,160.062,0.000,320.000
gpt-post-process,3832.465,3566.772,150.000,70.000,62.500,200.102,99.898,0.000
