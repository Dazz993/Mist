op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1707.613,1923.603,0.031,64.000,82.000,64.070,191.930,320.000
enc-1st-layernorm,139.928,503.212,64.000,128.000,0.000,64.062,0.000,512.000
enc-attention-qkv,500.423,1296.735,128.000,88.000,12.000,24.000,0.000,124.000
enc-attention-score,383.317,503.170,88.000,328.000,0.000,256.000,256.000,552.000
enc-attention-softmax,622.261,619.769,328.000,328.000,0.000,256.000,0.000,768.000
enc-attention-dropout,580.877,492.358,328.000,328.000,0.000,384.000,0.000,1024.000
enc-attention-context,263.417,630.045,328.000,72.000,0.000,8.000,12.000,272.000
enc-attention-dense,840.098,146.180,72.000,128.008,4.000,64.000,0.000,212.000
enc-post-attention-dropout,441.974,226.378,128.008,64.000,0.000,96.000,64.000,364.000
enc-2nd-layernorm,138.021,507.098,64.000,128.000,0.000,64.062,0.000,512.000
enc-MLP-GEMM-1,557.464,1366.377,128.000,96.004,16.000,32.000,0.000,160.000
enc-MLP-gelu,62.919,130.373,96.004,96.000,0.000,32.000,0.000,236.000
enc-MLP-GEMM-2,1298.559,504.619,96.000,128.008,16.000,64.000,0.000,224.000
enc-post-MLP-dropout,442.201,226.539,128.008,64.000,0.000,96.000,64.000,364.000
final-layernorm,298.375,408.059,64.000,64.000,0.000,128.062,0.000,256.000
gpt-post-process,3632.814,3019.154,64.000,0.000,50.000,200.102,99.898,0.000
