op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,2027.845,2530.032,0.031,80.000,165.000,80.070,239.930,558.000
enc-1st-layernorm,184.846,705.969,80.000,160.000,0.000,80.062,0.000,640.000
enc-attention-qkv,1489.073,2263.832,160.000,140.000,37.500,60.000,20.000,260.000
enc-attention-score,909.781,1509.249,140.000,740.000,0.000,640.000,640.000,1340.000
enc-attention-softmax,1524.198,1537.293,740.000,740.000,0.000,640.000,0.000,1920.000
enc-attention-dropout,1444.769,1220.047,740.000,740.000,0.000,960.000,0.000,2560.000
enc-attention-context,652.134,1440.233,740.000,100.000,0.000,20.000,20.000,700.000
enc-attention-dense,1261.348,378.424,100.000,160.010,12.500,80.000,0.000,260.000
enc-post-attention-dropout,558.931,281.364,160.010,80.000,0.000,120.000,80.000,430.000
enc-2nd-layernorm,181.019,677.186,80.000,160.000,0.000,80.062,0.000,640.000
enc-MLP-GEMM-1,1687.258,2518.672,160.000,160.010,50.000,80.000,0.000,320.000
enc-MLP-gelu,150.853,281.554,160.010,160.000,0.000,80.000,0.000,430.000
enc-MLP-GEMM-2,2404.916,1529.306,160.000,160.010,50.000,80.000,0.000,320.000
enc-post-MLP-dropout,551.617,283.587,160.010,80.000,0.000,120.000,80.000,430.000
final-layernorm,390.190,494.087,80.000,80.000,0.000,160.062,0.000,320.000
gpt-post-process,7149.690,5850.852,80.000,0.000,125.000,400.102,199.898,0.000
