op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1169.002,1631.951,0.016,48.000,123.000,48.035,0.000,356.000
enc-1st-layernorm,126.994,440.866,48.000,96.000,0.000,48.031,0.000,384.000
enc-attention-qkv,526.714,1103.306,96.000,66.000,27.000,18.000,2.000,98.000
enc-attention-score,370.449,492.954,66.000,310.000,0.000,256.000,256.000,532.000
enc-attention-softmax,622.344,620.556,310.000,310.000,0.000,256.000,0.000,768.000
enc-attention-dropout,579.005,492.150,310.000,310.000,0.000,384.000,0.000,1024.000
enc-attention-context,259.340,612.777,310.000,54.000,0.000,6.000,14.000,276.000
enc-attention-dense,727.534,169.677,54.000,96.012,9.000,48.000,0.000,164.000
enc-post-attention-dropout,336.564,172.317,96.012,48.000,0.000,72.000,48.000,300.000
enc-2nd-layernorm,125.694,440.741,48.000,96.000,0.000,48.031,0.000,384.000
enc-MLP-GEMM-1,638.986,1290.417,96.000,72.006,36.000,24.000,0.000,120.000
enc-MLP-gelu,49.257,96.351,72.006,72.000,0.000,24.000,0.000,192.000
enc-MLP-GEMM-2,1233.429,601.608,72.000,96.012,36.000,48.000,0.000,168.000
enc-post-MLP-dropout,336.576,172.484,96.012,48.000,0.000,72.000,48.000,300.000
final-layernorm,125.623,331.020,48.000,48.000,0.000,48.031,0.000,192.000
gpt-post-process,2330.714,2318.072,48.000,0.000,75.000,100.051,49.949,0.000
