op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1554.990,2423.596,0.031,64.000,232.000,64.070,191.930,548.000
enc-1st-layernorm,139.976,524.616,64.000,128.000,0.000,64.062,0.000,512.000
enc-attention-qkv,1956.952,2290.022,128.000,160.000,48.000,96.000,96.000,352.000
enc-attention-score,1419.258,1938.027,160.000,1120.000,0.000,1024.000,1024.000,2144.000
enc-attention-softmax,2415.258,2446.669,1120.000,1120.000,0.000,1024.000,0.000,3072.000
enc-attention-dropout,2321.613,1951.194,1120.000,1120.000,0.000,1536.000,0.000,4096.000
enc-attention-context,1016.986,2338.976,1120.000,96.000,0.000,32.000,32.000,1120.000
enc-attention-dense,1115.960,507.998,96.000,128.008,16.000,64.000,0.000,224.000
enc-post-attention-dropout,453.955,232.756,128.008,64.000,0.000,96.000,64.000,364.000
enc-2nd-layernorm,138.313,524.449,64.000,128.000,0.000,64.062,0.000,512.000
enc-MLP-GEMM-1,2244.222,2545.840,128.000,192.016,64.000,128.000,0.000,448.000
enc-MLP-gelu,230.306,428.653,192.016,192.000,0.000,128.000,0.000,620.000
enc-MLP-GEMM-2,2690.667,2003.199,192.000,128.008,64.000,64.000,0.000,320.000
enc-post-MLP-dropout,445.408,227.624,128.008,64.000,0.000,96.000,64.000,364.000
final-layernorm,298.738,407.630,64.000,64.000,0.000,128.062,0.000,256.000
gpt-post-process,12315.404,9020.227,64.000,0.000,200.000,800.102,399.898,0.000
