op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,197912.097,825.334,0.008,8.000,58.000,8.018,11.982,86.000
enc-1st-layernorm,58.150,122.714,8.000,16.000,0.000,8.016,0.000,72.000
enc-attention-qkv,232.697,552.630,16.000,14.000,6.000,6.000,0.000,20.000
enc-attention-score,134.349,240.165,14.000,74.000,0.000,64.000,64.000,128.000
enc-attention-softmax,162.327,217.152,74.000,74.000,0.000,64.000,0.000,192.000
enc-attention-dropout,246.036,213.677,74.000,74.000,0.000,96.000,0.000,256.000
enc-attention-context,144.476,237.089,74.000,10.000,0.000,2.000,0.000,64.000
enc-attention-dense,415.659,87.047,10.000,16.004,2.000,8.000,0.000,36.000
enc-post-attention-dropout,110.555,66.352,16.004,8.000,0.000,12.000,8.000,72.000
enc-2nd-layernorm,59.497,120.360,8.000,16.000,0.000,8.016,11.984,72.000
enc-MLP-GEMM-1,225.121,513.935,16.000,16.004,8.000,8.000,0.000,36.000
enc-MLP-gelu,56.338,98.705,16.004,16.000,0.000,8.000,12.000,68.000
enc-MLP-GEMM-2,557.429,213.903,16.000,16.004,8.000,8.000,0.000,36.000
enc-post-MLP-dropout,101.423,61.947,16.004,8.000,0.000,12.000,8.000,72.000
final-layernorm,62.454,282.365,8.000,8.000,0.000,8.016,11.984,36.000
gpt-post-process,2724.844,2124.649,8.000,0.000,50.000,100.025,49.975,0.000
