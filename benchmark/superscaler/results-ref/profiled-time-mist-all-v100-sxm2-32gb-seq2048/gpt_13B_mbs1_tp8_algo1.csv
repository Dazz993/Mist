op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,809.181,1123.977,0.008,20.000,82.500,20.018,0.000,124.000
enc-1st-layernorm,118.285,337.350,20.000,40.000,0.000,20.016,0.000,160.000
enc-attention-qkv,1945.800,680.125,22.500,80.000,18.750,60.000,60.000,180.000
enc-attention-score,125.027,203.377,45.000,80.000,0.000,40.000,40.000,80.000
enc-attention-softmax,1088.953,1761.907,80.000,80.000,0.000,120.000,80.000,280.000
enc-attention-dropout,156.868,140.458,80.000,80.000,0.000,60.000,0.000,160.000
enc-attention-context,114.483,211.054,80.000,40.000,0.000,2.500,0.000,40.000
enc-attention-dense,641.936,186.282,40.000,57.510,6.250,20.000,0.000,60.000
enc-post-attention-dropout,232.303,124.359,57.510,37.500,0.000,30.000,20.000,160.000
enc-2nd-layernorm,117.403,337.195,37.500,57.500,0.000,20.016,0.000,160.000
enc-MLP-GEMM-1,583.518,1004.565,57.500,47.505,25.000,10.000,0.000,50.000
enc-MLP-gelu,49.978,80.264,47.505,47.500,0.000,10.000,0.000,80.000
enc-MLP-GEMM-2,1058.453,494.605,47.500,57.510,25.000,20.000,0.000,70.000
enc-post-MLP-dropout,232.792,125.110,57.510,37.500,0.000,30.000,20.000,160.000
final-layernorm,117.624,281.662,37.500,37.500,0.000,20.016,0.000,80.000
gpt-post-process,2359.205,2176.118,37.500,17.500,62.500,50.025,25.975,0.000
