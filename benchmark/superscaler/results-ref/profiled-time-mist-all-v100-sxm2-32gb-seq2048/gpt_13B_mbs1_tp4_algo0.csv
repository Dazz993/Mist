op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,887.215,1463.377,0.008,20.000,145.000,20.018,0.000,126.000
enc-1st-layernorm,118.423,335.008,20.000,40.000,0.000,20.016,0.000,160.000
enc-attention-qkv,938.267,1515.782,40.000,35.000,37.500,16.000,0.000,76.000
enc-attention-score,258.851,322.837,35.000,105.000,0.000,80.000,80.000,180.000
enc-attention-softmax,2151.394,3494.239,105.000,105.000,0.000,240.000,160.000,560.000
enc-attention-dropout,314.265,264.490,105.000,105.000,0.000,120.000,0.000,320.000
enc-attention-context,219.983,378.656,105.000,25.000,0.000,5.000,0.000,110.000
enc-attention-dense,871.629,247.985,25.000,40.010,12.500,20.000,0.000,60.000
enc-post-attention-dropout,232.816,124.413,40.010,20.000,0.000,30.000,10.000,160.000
enc-2nd-layernorm,117.970,340.229,20.000,40.000,0.000,20.016,0.000,160.000
enc-MLP-GEMM-1,1176.924,1814.985,40.000,40.010,50.000,20.000,0.000,80.000
enc-MLP-gelu,63.390,131.303,40.010,40.000,0.000,20.000,0.000,160.000
enc-MLP-GEMM-2,1787.764,1031.595,40.000,40.010,50.000,20.000,0.000,80.000
enc-post-MLP-dropout,235.027,124.741,40.010,20.000,0.000,30.000,10.000,160.000
final-layernorm,119.764,276.202,20.000,20.000,0.000,20.016,0.000,80.000
gpt-post-process,4370.755,3676.456,20.000,0.000,125.000,100.025,49.975,0.000
