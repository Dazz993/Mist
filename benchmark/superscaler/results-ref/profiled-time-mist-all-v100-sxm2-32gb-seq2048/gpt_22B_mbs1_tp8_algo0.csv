op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,932.217,1669.949,0.008,24.000,99.000,24.018,0.000,0.000
enc-1st-layernorm,147.283,401.282,24.000,48.000,0.000,24.016,0.000,192.000
enc-attention-qkv,714.648,1290.047,48.000,33.000,27.000,9.875,0.000,44.000
enc-attention-score,165.707,266.546,33.000,91.000,0.000,64.000,64.000,128.000
enc-attention-softmax,161.135,214.034,91.000,91.000,0.000,64.000,0.000,192.000
enc-attention-dropout,245.649,215.715,91.000,91.000,0.000,96.000,0.000,256.000
enc-attention-context,143.206,277.710,91.000,27.000,0.000,3.000,0.000,84.000
enc-attention-dense,763.637,229.168,27.000,48.012,9.000,24.000,0.000,72.000
enc-post-attention-dropout,276.810,148.177,48.012,24.000,0.000,36.000,24.000,178.000
enc-2nd-layernorm,147.688,399.959,24.000,48.000,0.000,24.016,0.000,192.000
enc-MLP-GEMM-1,877.267,1431.519,48.000,36.006,36.000,12.000,0.000,60.000
enc-MLP-gelu,47.052,82.642,36.006,36.000,0.000,12.000,0.000,96.000
enc-MLP-GEMM-2,1386.887,851.196,36.000,48.012,36.000,24.000,0.000,84.000
enc-post-MLP-dropout,278.592,151.306,48.012,24.000,0.000,36.000,24.000,178.000
final-layernorm,148.743,299.609,24.000,24.000,0.000,24.016,0.000,96.000
gpt-post-process,2596.813,2531.970,24.000,0.000,75.000,50.025,25.975,0.000
