op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1845.568,2304.995,0.016,40.000,145.000,40.035,119.965,342.000
enc-1st-layernorm,219.685,651.628,40.000,80.000,0.000,40.031,0.000,320.000
enc-attention-qkv,5276.132,1921.320,50.000,160.000,37.500,120.000,120.000,370.000
enc-attention-score,513.142,756.115,100.000,240.000,0.000,160.000,160.000,350.000
enc-attention-softmax,396.711,516.480,240.000,240.000,0.000,160.000,0.000,480.000
enc-attention-dropout,606.692,521.737,240.000,240.000,0.000,240.000,0.000,640.000
enc-attention-context,425.571,795.650,240.000,80.000,0.000,10.000,10.000,190.000
enc-attention-dense,1600.248,498.313,80.000,110.010,12.500,40.000,0.000,120.000
enc-post-attention-dropout,453.055,240.940,110.010,70.000,0.000,60.000,40.000,240.000
enc-2nd-layernorm,209.707,656.521,70.000,110.000,0.000,40.031,0.000,320.000
enc-MLP-GEMM-1,2399.808,3354.299,110.000,110.010,50.000,40.000,0.000,160.000
enc-MLP-gelu,119.966,232.249,110.010,110.000,0.000,40.000,0.000,240.000
enc-MLP-GEMM-2,3356.266,2135.974,110.000,110.010,50.000,40.000,0.000,160.000
enc-post-MLP-dropout,459.975,243.574,110.010,70.000,0.000,60.000,40.000,240.000
final-layernorm,364.423,503.701,70.000,70.000,0.000,80.031,0.000,160.000
gpt-post-process,8110.714,6853.664,70.000,30.000,125.000,200.051,99.949,0.000
