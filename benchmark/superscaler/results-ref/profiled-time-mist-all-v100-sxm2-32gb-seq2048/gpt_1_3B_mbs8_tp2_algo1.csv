op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,5026.221,3016.710,0.062,64.000,108.000,64.141,191.859,548.000
enc-1st-layernorm,228.345,948.322,64.000,128.000,0.000,64.125,0.000,512.000
enc-attention-qkv,14017.653,2816.391,96.000,256.000,12.000,192.000,192.000,608.000
enc-attention-score,2116.024,4179.859,192.000,1152.000,0.000,1024.000,1024.000,2144.000
enc-attention-softmax,2536.857,3351.617,1152.000,1152.000,0.000,1024.000,0.000,3072.000
enc-attention-dropout,3967.750,3295.499,1152.000,1152.000,0.000,1536.000,0.000,4096.000
enc-attention-context,3017.169,3422.791,1152.000,128.000,0.000,32.000,32.000,1120.000
enc-attention-dense,4451.585,692.809,128.000,160.004,4.000,64.000,0.000,224.000
enc-post-attention-dropout,763.923,391.346,160.004,96.000,0.000,96.000,64.000,336.000
enc-2nd-layernorm,213.361,884.897,96.000,160.000,0.000,64.125,0.000,512.000
enc-MLP-GEMM-1,3285.253,6729.060,160.000,224.008,16.000,128.000,0.000,448.000
enc-MLP-gelu,364.673,687.164,224.008,224.000,0.000,128.000,0.000,592.000
enc-MLP-GEMM-2,6599.402,2723.336,224.000,160.004,16.000,64.000,0.000,320.000
enc-post-MLP-dropout,717.127,382.614,160.004,96.000,0.000,96.000,64.000,336.000
final-layernorm,435.263,642.967,96.000,96.000,0.000,128.125,0.000,256.000
gpt-post-process,36995.471,26825.595,96.000,32.000,100.000,1600.203,799.797,0.000
