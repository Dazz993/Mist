op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1313.883,1511.824,0.031,32.000,33.000,32.070,95.930,154.000
enc-1st-layernorm,112.557,441.533,32.000,64.000,0.000,32.062,0.000,256.000
enc-attention-qkv,381.678,984.514,64.000,44.000,3.000,12.000,0.000,72.000
enc-attention-score,256.038,592.494,44.000,164.000,0.000,128.000,128.000,276.000
enc-attention-softmax,315.273,418.550,164.000,164.000,0.000,128.000,0.000,384.000
enc-attention-dropout,488.168,418.603,164.000,164.000,0.000,192.000,0.000,512.000
enc-attention-context,357.604,495.517,164.000,36.000,0.000,4.000,0.000,148.000
enc-attention-dense,760.567,110.883,36.000,64.004,1.000,32.000,0.000,96.000
enc-post-attention-dropout,364.268,194.246,64.004,32.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,114.781,444.698,32.000,64.000,0.000,32.062,0.000,256.000
enc-MLP-GEMM-1,420.320,1041.442,64.000,48.002,4.000,16.000,0.000,80.000
enc-MLP-gelu,50.938,110.477,48.002,48.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,1071.918,375.646,48.000,64.004,4.000,32.000,0.000,112.000
enc-post-MLP-dropout,364.202,193.781,64.004,32.000,0.000,48.000,32.000,208.000
final-layernorm,227.231,453.120,32.000,32.000,0.000,64.062,0.000,128.000
gpt-post-process,4998.887,4079.491,32.000,0.000,25.000,200.102,99.898,0.000
