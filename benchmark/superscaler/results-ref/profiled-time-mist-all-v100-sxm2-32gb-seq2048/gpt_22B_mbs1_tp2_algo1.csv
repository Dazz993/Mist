op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1870.316,2837.443,0.008,24.000,324.000,24.018,0.000,396.000
enc-1st-layernorm,154.173,415.355,24.000,48.000,0.000,24.016,0.000,192.000
enc-attention-qkv,7160.091,2485.800,36.000,96.000,108.000,72.000,0.000,228.000
enc-attention-score,665.385,1194.578,72.000,304.000,0.000,256.000,256.000,548.000
enc-attention-softmax,636.232,823.355,304.000,304.000,0.000,256.000,0.000,768.000
enc-attention-dropout,979.298,828.433,304.000,304.000,0.000,384.000,0.000,1024.000
enc-attention-context,751.930,1149.654,304.000,48.000,0.000,12.000,12.000,292.000
enc-attention-dense,2359.390,850.600,48.000,60.012,36.000,24.000,0.000,84.000
enc-post-attention-dropout,277.442,147.682,60.012,36.000,0.000,36.000,24.000,178.000
enc-2nd-layernorm,148.475,403.047,36.000,60.000,0.000,24.016,0.000,192.000
enc-MLP-GEMM-1,3581.828,4942.435,60.000,84.023,144.000,48.000,0.000,168.000
enc-MLP-gelu,140.625,274.366,84.023,84.000,0.000,48.000,0.000,276.000
enc-MLP-GEMM-2,5244.136,3051.066,84.000,60.012,144.000,24.000,0.000,120.000
enc-post-MLP-dropout,278.568,147.319,60.012,36.000,0.000,36.000,24.000,178.000
final-layernorm,151.438,305.378,36.000,36.000,0.000,24.016,0.000,96.000
gpt-post-process,8933.902,8498.412,36.000,12.000,300.000,200.025,99.975,0.000
