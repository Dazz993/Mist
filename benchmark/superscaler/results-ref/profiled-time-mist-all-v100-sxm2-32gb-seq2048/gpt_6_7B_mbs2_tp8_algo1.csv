op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1307.243,1614.225,0.016,32.000,66.000,32.035,95.965,226.000
enc-1st-layernorm,154.608,492.907,32.000,64.000,0.000,32.031,0.000,256.000
enc-attention-qkv,2836.376,961.852,36.000,128.000,12.000,96.000,96.000,288.000
enc-attention-score,183.833,274.998,72.000,128.000,0.000,64.000,64.000,148.000
enc-attention-softmax,160.569,213.957,128.000,128.000,0.000,64.000,0.000,192.000
enc-attention-dropout,245.583,213.033,128.000,128.000,0.000,96.000,0.000,256.000
enc-attention-context,144.780,296.879,128.000,64.000,0.000,4.000,0.000,84.000
enc-attention-dense,882.375,200.498,64.000,92.008,4.000,32.000,0.000,96.000
enc-post-attention-dropout,364.780,194.031,92.008,60.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,155.854,494.790,60.000,92.000,0.000,32.031,0.000,256.000
enc-MLP-GEMM-1,827.140,1509.023,92.000,76.004,16.000,16.000,0.000,80.000
enc-MLP-gelu,50.843,106.978,76.004,76.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,1477.087,757.354,76.000,92.008,16.000,32.000,0.000,112.000
enc-post-MLP-dropout,365.722,194.705,92.008,60.000,0.000,48.000,32.000,208.000
final-layernorm,270.951,451.714,60.000,60.000,0.000,64.031,0.000,128.000
gpt-post-process,3694.713,3615.868,60.000,28.000,50.000,100.051,49.949,0.000
