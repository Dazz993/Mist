op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,809.181,1123.977,0.008,20.000,82.500,20.018,0.000,124.000
enc-1st-layernorm,118.285,337.350,20.000,40.000,0.000,20.016,0.000,160.000
enc-attention-qkv,529.844,902.575,40.000,27.500,18.750,7.500,0.000,40.000
enc-attention-score,125.027,203.377,27.500,62.500,0.000,40.000,40.000,80.000
enc-attention-softmax,1088.953,1761.907,62.500,62.500,0.000,120.000,80.000,280.000
enc-attention-dropout,156.868,140.458,62.500,62.500,0.000,60.000,0.000,160.000
enc-attention-context,114.483,211.054,62.500,22.500,0.000,2.500,0.000,40.000
enc-attention-dense,661.403,186.062,22.500,40.010,6.250,20.000,0.000,60.000
enc-post-attention-dropout,232.303,124.359,40.010,20.000,0.000,30.000,20.000,160.000
enc-2nd-layernorm,117.403,337.195,20.000,40.000,0.000,20.016,0.000,160.000
enc-MLP-GEMM-1,583.678,997.645,40.000,30.005,25.000,10.000,0.000,50.000
enc-MLP-gelu,49.978,80.264,30.005,30.000,0.000,10.000,0.000,80.000
enc-MLP-GEMM-2,1052.827,487.274,30.000,40.010,25.000,20.000,0.000,70.000
enc-post-MLP-dropout,232.792,125.110,40.010,20.000,0.000,30.000,20.000,160.000
final-layernorm,117.624,281.662,20.000,20.000,0.000,20.016,0.000,80.000
gpt-post-process,2359.205,2176.118,20.000,0.000,62.500,50.025,25.975,0.000
