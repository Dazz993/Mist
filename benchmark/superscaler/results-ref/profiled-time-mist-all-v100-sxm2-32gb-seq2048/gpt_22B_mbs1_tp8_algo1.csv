op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,932.217,1669.949,0.008,24.000,99.000,24.018,0.000,0.000
enc-1st-layernorm,147.283,401.282,24.000,48.000,0.000,24.016,0.000,192.000
enc-attention-qkv,2414.387,843.239,27.000,96.000,27.000,72.000,72.000,216.000
enc-attention-score,165.707,266.546,54.000,112.000,0.000,64.000,64.000,128.000
enc-attention-softmax,161.135,214.034,112.000,112.000,0.000,64.000,0.000,192.000
enc-attention-dropout,245.649,215.715,112.000,112.000,0.000,96.000,0.000,256.000
enc-attention-context,143.206,277.710,112.000,48.000,0.000,3.000,0.000,84.000
enc-attention-dense,772.029,232.404,48.000,69.012,9.000,24.000,0.000,72.000
enc-post-attention-dropout,276.810,148.177,69.012,45.000,0.000,36.000,24.000,178.000
enc-2nd-layernorm,147.688,399.959,45.000,69.000,0.000,24.016,0.000,192.000
enc-MLP-GEMM-1,882.250,1440.084,69.000,57.006,36.000,12.000,0.000,60.000
enc-MLP-gelu,47.052,82.642,57.006,57.000,0.000,12.000,0.000,96.000
enc-MLP-GEMM-2,1408.297,847.971,57.000,69.012,36.000,24.000,0.000,84.000
enc-post-MLP-dropout,278.592,151.306,69.012,45.000,0.000,36.000,24.000,178.000
final-layernorm,148.743,299.609,45.000,45.000,0.000,24.016,0.000,96.000
gpt-post-process,2596.813,2531.970,45.000,21.000,75.000,50.025,25.975,0.000
