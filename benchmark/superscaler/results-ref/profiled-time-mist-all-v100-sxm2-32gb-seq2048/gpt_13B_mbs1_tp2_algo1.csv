op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1573.586,2201.134,0.008,20.000,270.000,20.018,19.982,330.000
enc-1st-layernorm,124.109,345.808,20.000,40.000,0.000,20.016,0.000,160.000
enc-attention-qkv,5601.335,1770.115,30.000,80.000,75.000,60.000,60.000,170.000
enc-attention-score,507.605,733.405,60.000,200.000,0.000,160.000,160.000,350.000
enc-attention-softmax,391.829,518.638,200.000,200.000,0.000,160.000,0.000,480.000
enc-attention-dropout,616.252,521.606,200.000,200.000,0.000,240.000,0.000,640.000
enc-attention-context,449.401,795.788,200.000,40.000,0.000,10.000,10.000,190.000
enc-attention-dense,1833.582,485.665,40.000,50.010,25.000,20.000,0.000,60.000
enc-post-attention-dropout,233.537,124.007,50.010,30.000,0.000,30.000,10.000,160.000
enc-2nd-layernorm,117.826,333.923,30.000,50.000,0.000,20.016,0.000,160.000
enc-MLP-GEMM-1,2418.715,3623.939,50.000,70.020,100.000,40.000,0.000,140.000
enc-MLP-gelu,118.309,232.321,70.020,70.000,0.000,40.000,0.000,240.000
enc-MLP-GEMM-2,3622.538,2120.960,70.000,50.010,100.000,20.000,0.000,100.000
enc-post-MLP-dropout,236.624,124.401,50.010,30.000,0.000,30.000,10.000,160.000
final-layernorm,122.941,287.551,30.000,30.000,0.000,20.016,0.000,80.000
gpt-post-process,8071.858,7168.257,30.000,10.000,250.000,200.025,99.975,0.000
