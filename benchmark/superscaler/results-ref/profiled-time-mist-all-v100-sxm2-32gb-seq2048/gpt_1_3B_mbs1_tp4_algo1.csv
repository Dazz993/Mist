op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,197912.097,825.334,0.008,8.000,58.000,8.018,11.982,86.000
enc-1st-layernorm,58.150,122.714,8.000,16.000,0.000,8.016,0.000,72.000
enc-attention-qkv,1001.447,263.131,10.000,32.000,6.000,24.000,24.000,76.000
enc-attention-score,134.349,240.165,20.000,80.000,0.000,64.000,64.000,128.000
enc-attention-softmax,162.327,217.152,80.000,80.000,0.000,64.000,0.000,192.000
enc-attention-dropout,246.036,213.677,80.000,80.000,0.000,96.000,0.000,256.000
enc-attention-context,144.476,237.089,80.000,16.000,0.000,2.000,0.000,64.000
enc-attention-dense,404.477,86.886,16.000,22.004,2.000,8.000,0.000,36.000
enc-post-attention-dropout,110.555,66.352,22.004,14.000,0.000,12.000,8.000,72.000
enc-2nd-layernorm,59.497,120.360,14.000,22.000,0.000,8.016,11.984,72.000
enc-MLP-GEMM-1,224.346,504.386,22.000,22.004,8.000,8.000,0.000,36.000
enc-MLP-gelu,56.338,98.705,22.004,22.000,0.000,8.000,12.000,68.000
enc-MLP-GEMM-2,524.211,212.497,22.000,22.004,8.000,8.000,0.000,36.000
enc-post-MLP-dropout,101.423,61.947,22.004,14.000,0.000,12.000,8.000,72.000
final-layernorm,62.454,282.365,14.000,14.000,0.000,8.016,11.984,36.000
gpt-post-process,2724.844,2124.649,14.000,6.000,50.000,100.025,49.975,0.000
