op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1307.243,1614.225,0.016,32.000,66.000,32.035,95.965,226.000
enc-1st-layernorm,154.608,492.907,32.000,64.000,0.000,32.031,0.000,256.000
enc-attention-qkv,648.260,1382.381,64.000,44.000,12.000,12.000,0.000,64.000
enc-attention-score,183.833,274.998,44.000,100.000,0.000,64.000,64.000,148.000
enc-attention-softmax,160.569,213.957,100.000,100.000,0.000,64.000,0.000,192.000
enc-attention-dropout,245.583,213.033,100.000,100.000,0.000,96.000,0.000,256.000
enc-attention-context,144.780,296.879,100.000,36.000,0.000,4.000,0.000,84.000
enc-attention-dense,896.686,202.423,36.000,64.008,4.000,32.000,0.000,96.000
enc-post-attention-dropout,364.780,194.031,64.008,32.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,155.854,494.790,32.000,64.000,0.000,32.031,0.000,256.000
enc-MLP-GEMM-1,826.651,1496.416,64.000,48.004,16.000,16.000,0.000,80.000
enc-MLP-gelu,50.843,106.978,48.004,48.000,0.000,16.000,0.000,128.000
enc-MLP-GEMM-2,1449.770,757.122,48.000,64.008,16.000,32.000,0.000,112.000
enc-post-MLP-dropout,365.722,194.705,64.008,32.000,0.000,48.000,32.000,208.000
final-layernorm,270.951,451.714,32.000,32.000,0.000,64.031,0.000,128.000
gpt-post-process,3694.713,3615.868,32.000,0.000,50.000,100.051,49.949,0.000
