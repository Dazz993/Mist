op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,2469.802,2476.716,0.062,64.000,33.000,64.141,191.859,192.000
enc-1st-layernorm,211.197,895.613,64.000,128.000,0.000,64.125,0.000,512.000
enc-attention-qkv,692.213,1890.880,128.000,88.000,3.000,24.000,20.000,140.000
enc-attention-score,509.626,1132.572,88.000,328.000,0.000,256.000,256.000,532.000
enc-attention-softmax,620.061,842.971,328.000,328.000,0.000,256.000,0.000,768.000
enc-attention-dropout,959.402,830.096,328.000,328.000,0.000,384.000,0.000,1024.000
enc-attention-context,639.182,897.926,328.000,72.000,0.000,8.000,12.000,292.000
enc-attention-dense,1315.242,224.394,72.000,128.004,1.000,64.000,0.000,212.000
enc-post-attention-dropout,717.729,380.528,128.004,64.000,0.000,96.000,64.000,336.000
enc-2nd-layernorm,210.464,911.009,64.000,128.000,0.000,64.125,0.000,512.000
enc-MLP-GEMM-1,775.927,2004.933,128.000,96.002,4.000,32.000,0.000,160.000
enc-MLP-gelu,95.350,202.215,96.002,96.000,0.000,32.000,0.000,208.000
enc-MLP-GEMM-2,1905.179,694.656,96.000,128.004,4.000,64.000,0.000,224.000
enc-post-MLP-dropout,718.015,380.284,128.004,64.000,0.000,96.000,64.000,336.000
final-layernorm,433.064,650.913,64.000,64.000,0.000,128.125,0.000,256.000
gpt-post-process,9631.723,7176.799,64.000,0.000,25.000,400.203,199.797,0.000
