op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1484.317,1664.215,0.031,32.000,58.000,32.070,95.930,218.000
enc-1st-layernorm,113.118,437.248,32.000,64.000,0.000,32.062,0.000,256.000
enc-attention-qkv,678.188,1598.775,64.000,56.000,6.000,24.000,20.000,108.000
enc-attention-score,502.282,1183.236,56.000,296.000,0.000,256.000,256.000,532.000
enc-attention-softmax,625.587,852.305,296.000,296.000,0.000,256.000,0.000,768.000
enc-attention-dropout,975.734,830.013,296.000,296.000,0.000,384.000,0.000,1024.000
enc-attention-context,720.549,905.669,296.000,40.000,0.000,8.000,12.000,292.000
enc-attention-dense,1038.247,207.263,40.000,64.004,2.000,32.000,0.000,116.000
enc-post-attention-dropout,366.080,194.246,64.004,32.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,112.915,432.128,32.000,64.000,0.000,32.062,0.000,256.000
enc-MLP-GEMM-1,815.105,1697.475,64.000,64.004,8.000,32.000,0.000,128.000
enc-MLP-gelu,95.409,194.436,64.004,64.000,0.000,32.000,0.000,208.000
enc-MLP-GEMM-2,1628.178,737.005,64.000,64.004,8.000,32.000,0.000,128.000
enc-post-MLP-dropout,365.746,194.269,64.004,32.000,0.000,48.000,32.000,208.000
final-layernorm,227.505,444.454,32.000,32.000,0.000,64.062,0.000,128.000
gpt-post-process,9572.601,7171.142,32.000,0.000,50.000,400.102,199.898,0.000
