op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1482.528,1882.070,0.016,32.000,116.000,32.035,95.965,324.000
enc-1st-layernorm,156.534,491.738,32.000,64.000,0.000,32.031,0.000,256.000
enc-attention-qkv,4026.437,1433.039,40.000,128.000,24.000,96.000,96.000,288.000
enc-attention-score,361.317,691.974,80.000,192.000,0.000,128.000,128.000,276.000
enc-attention-softmax,314.236,411.600,192.000,192.000,0.000,128.000,0.000,384.000
enc-attention-dropout,483.024,419.056,192.000,192.000,0.000,192.000,0.000,512.000
enc-attention-context,354.677,627.261,192.000,64.000,0.000,8.000,12.000,164.000
enc-attention-dense,1240.319,389.391,64.000,88.008,8.000,32.000,0.000,96.000
enc-post-attention-dropout,364.387,193.805,88.008,56.000,0.000,48.000,32.000,208.000
enc-2nd-layernorm,155.431,496.811,56.000,88.000,0.000,32.031,0.000,256.000
enc-MLP-GEMM-1,1586.425,2475.029,88.000,88.008,32.000,32.000,0.000,128.000
enc-MLP-gelu,97.001,193.137,88.008,88.000,0.000,32.000,0.000,208.000
enc-MLP-GEMM-2,2422.065,1395.088,88.000,88.008,32.000,32.000,0.000,128.000
enc-post-MLP-dropout,366.569,194.252,88.008,56.000,0.000,48.000,32.000,208.000
final-layernorm,277.126,448.841,56.000,56.000,0.000,64.031,0.000,128.000
gpt-post-process,6916.225,6039.876,56.000,24.000,100.000,200.051,99.949,0.000
