op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,2106.839,2266.520,0.031,80.000,102.500,80.070,239.930,398.000
enc-1st-layernorm,184.840,672.609,80.000,160.000,0.000,80.062,0.000,640.000
enc-attention-qkv,745.338,1663.047,160.000,110.000,18.750,30.000,0.000,170.000
enc-attention-score,477.803,607.109,110.000,410.000,0.000,320.000,320.000,670.000
enc-attention-softmax,4889.584,7823.443,410.000,410.000,0.000,960.000,640.000,2240.000
enc-attention-dropout,722.003,618.041,410.000,410.000,0.000,480.000,0.000,1280.000
enc-attention-context,342.071,759.810,410.000,90.000,0.000,10.000,10.000,350.000
enc-attention-dense,1089.084,214.183,90.000,160.010,6.250,80.000,0.000,250.000
enc-post-attention-dropout,550.646,281.358,160.010,80.000,0.000,120.000,80.000,430.000
enc-2nd-layernorm,180.954,676.668,80.000,160.000,0.000,80.062,0.000,640.000
enc-MLP-GEMM-1,818.068,1785.868,160.000,120.005,25.000,40.000,0.000,200.000
enc-MLP-gelu,76.783,154.555,120.005,120.000,0.000,40.000,0.000,270.000
enc-MLP-GEMM-2,1793.075,764.972,120.000,160.010,25.000,80.000,0.000,280.000
enc-post-MLP-dropout,552.446,280.517,160.010,80.000,0.000,120.000,80.000,430.000
final-layernorm,392.830,490.785,80.000,80.000,0.000,160.062,0.000,320.000
gpt-post-process,3850.359,3609.848,80.000,0.000,62.500,200.102,99.898,0.000
