op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,602.835,1774.347,0.031,40.000,270.000,40.000,120.000,466.000
enc-1st-layernorm,89.431,315.481,40.000,80.000,0.000,40.062,0.000,320.000
enc-attention-qkv,1993.728,1571.417,80.000,160.000,37.500,120.000,120.000,400.000
enc-attention-score,2199.918,3426.421,160.000,2128.000,0.000,2048.000,2048.000,4216.000
enc-attention-softmax,4832.453,4830.080,2128.000,2128.000,0.000,2048.000,0.000,6144.000
enc-attention-dropout,4673.797,3898.263,2128.000,2128.000,0.000,3072.000,0.000,8192.000
enc-attention-context,1944.518,3882.223,2128.000,80.000,0.000,40.000,40.000,2168.000
enc-attention-dense,469.422,411.677,80.000,80.005,12.500,40.000,0.000,160.000
enc-post-attention-dropout,290.501,148.916,80.005,40.000,0.000,60.000,40.000,270.000
enc-2nd-layernorm,90.128,328.350,40.000,80.000,0.000,40.062,0.000,320.000
enc-MLP-GEMM-1,1939.029,1531.231,80.000,200.020,50.000,160.000,0.000,520.000
enc-MLP-gelu,292.218,545.943,200.020,200.000,0.000,160.000,0.000,750.000
enc-MLP-GEMM-2,1703.739,1665.652,200.000,80.005,50.000,40.000,0.000,280.000
enc-post-MLP-dropout,289.732,149.530,80.005,40.000,0.000,60.000,40.000,270.000
final-layernorm,192.010,391.382,40.000,40.000,0.000,80.062,0.000,160.000
gpt-post-process,19804.174,11961.728,40.000,0.000,250.000,1600.102,799.898,0.000
