op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,2106.839,2266.520,0.031,80.000,102.500,80.070,239.930,398.000
enc-1st-layernorm,184.840,672.609,80.000,160.000,0.000,80.062,0.000,640.000
enc-attention-qkv,3854.489,1168.525,90.000,320.000,18.750,240.000,240.000,720.000
enc-attention-score,477.803,607.109,180.000,480.000,0.000,320.000,320.000,670.000
enc-attention-softmax,4889.584,7823.443,480.000,480.000,0.000,960.000,640.000,2240.000
enc-attention-dropout,722.003,618.041,480.000,480.000,0.000,480.000,0.000,1280.000
enc-attention-context,342.071,759.810,480.000,160.000,0.000,10.000,10.000,350.000
enc-attention-dense,1085.627,214.183,160.000,230.010,6.250,80.000,0.000,250.000
enc-post-attention-dropout,550.646,281.358,230.010,150.000,0.000,120.000,80.000,430.000
enc-2nd-layernorm,180.954,676.668,150.000,230.000,0.000,80.062,0.000,640.000
enc-MLP-GEMM-1,820.142,1790.428,230.000,190.005,25.000,40.000,0.000,200.000
enc-MLP-gelu,76.783,154.555,190.005,190.000,0.000,40.000,0.000,270.000
enc-MLP-GEMM-2,1794.261,764.215,190.000,230.010,25.000,80.000,0.000,280.000
enc-post-MLP-dropout,552.446,280.517,230.010,150.000,0.000,120.000,80.000,430.000
final-layernorm,392.830,490.785,150.000,150.000,0.000,160.062,0.000,320.000
gpt-post-process,3850.359,3609.848,150.000,70.000,62.500,200.102,99.898,0.000
