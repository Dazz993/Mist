op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1707.482,1922.095,0.031,64.000,82.000,64.070,191.930,320.000
enc-1st-layernorm,137.979,502.986,64.000,128.000,0.000,64.062,0.000,512.000
enc-attention-qkv,502.002,1302.147,128.000,88.000,12.000,24.000,0.000,140.000
enc-attention-score,379.872,494.450,88.000,328.000,0.000,256.000,256.000,552.000
enc-attention-softmax,621.378,625.694,328.000,328.000,0.000,256.000,0.000,768.000
enc-attention-dropout,576.556,491.405,328.000,328.000,0.000,384.000,0.000,1024.000
enc-attention-context,261.170,628.197,328.000,72.000,0.000,8.000,12.000,272.000
enc-attention-dense,843.704,147.623,72.000,128.008,4.000,64.000,0.000,192.000
enc-post-attention-dropout,442.368,227.004,128.008,64.000,0.000,96.000,64.000,364.000
enc-2nd-layernorm,137.514,506.139,64.000,128.000,0.000,64.062,0.000,512.000
enc-MLP-GEMM-1,561.684,1358.783,128.000,96.004,16.000,32.000,0.000,160.000
enc-MLP-gelu,62.966,131.375,96.004,96.000,0.000,32.000,0.000,236.000
enc-MLP-GEMM-2,1291.162,505.483,96.000,128.008,16.000,64.000,0.000,224.000
enc-post-MLP-dropout,442.022,226.766,128.008,64.000,0.000,96.000,64.000,364.000
final-layernorm,297.713,450.802,64.000,64.000,0.000,128.062,0.000,256.000
gpt-post-process,3617.013,3071.344,64.000,0.000,50.000,200.102,99.898,0.000
