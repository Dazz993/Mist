op_name,forward-compute,backward-compute,input_size,output_size,weights,activations,fwd_reserved,bwd_reserved
encoder-embedding,1058.507,2319.509,0.016,48.000,348.000,48.035,0.000,502.000
enc-1st-layernorm,129.724,457.257,48.000,96.000,0.000,48.031,0.000,384.000
enc-attention-qkv,3554.082,2072.233,72.000,192.000,108.000,144.000,144.000,408.000
enc-attention-score,1273.191,1907.551,144.000,1120.000,0.000,1024.000,1024.000,2120.000
enc-attention-softmax,2427.268,2447.438,1120.000,1120.000,0.000,1024.000,0.000,3072.000
enc-attention-dropout,2325.541,1950.908,1120.000,1120.000,0.000,1536.000,0.000,4096.000
enc-attention-context,997.281,2180.099,1120.000,96.000,0.000,24.000,24.000,1096.000
enc-attention-dense,1106.995,605.947,96.000,120.012,36.000,48.000,0.000,168.000
enc-post-attention-dropout,344.342,177.526,120.012,72.000,0.000,72.000,48.000,300.000
enc-2nd-layernorm,129.575,459.349,72.000,120.000,0.000,48.031,0.000,384.000
enc-MLP-GEMM-1,2471.685,2916.080,120.000,168.023,144.000,96.000,0.000,336.000
enc-MLP-gelu,174.713,326.753,168.023,168.000,0.000,96.000,0.000,492.000
enc-MLP-GEMM-2,2947.336,2266.419,168.000,120.012,144.000,48.000,0.000,240.000
enc-post-MLP-dropout,337.607,173.116,120.012,72.000,0.000,72.000,48.000,300.000
final-layernorm,127.542,331.950,72.000,72.000,0.000,48.031,0.000,192.000
gpt-post-process,7853.895,6351.686,72.000,24.000,300.000,400.051,199.949,0.000
